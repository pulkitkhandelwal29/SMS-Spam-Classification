{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMS Spam Classification\n",
    "\n",
    "Natural Language Processing Using Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the csv file\n",
    "messages = pd.read_csv('SMSSpamCollection',sep='\\t',names = ['Label','Message'])\n",
    "\n",
    "#Specifying the names of the columns while reading csv file (tsv--tab separated values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            Message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Label    5572 non-null   object\n",
      " 1   Message  5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#Info about the data\n",
    "messages.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label      0\n",
       "Message    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding missing values\n",
    "messages.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape of the dataframe\n",
    "messages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Target variables counts\n",
    "messages['Label'].value_counts()\n",
    "\n",
    "#Data is imbalanced but for now we will continue with this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating length of message**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating length of message\n",
    "mes_len=0\n",
    "length=[]\n",
    "for i in range(len(messages)):\n",
    "    length.append(len(messages['Message'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[111,\n",
       " 29,\n",
       " 155,\n",
       " 49,\n",
       " 61,\n",
       " 147,\n",
       " 77,\n",
       " 160,\n",
       " 157,\n",
       " 154,\n",
       " 109,\n",
       " 136,\n",
       " 155,\n",
       " 196,\n",
       " 35,\n",
       " 149,\n",
       " 26,\n",
       " 81,\n",
       " 56,\n",
       " 155,\n",
       " 41,\n",
       " 47,\n",
       " 52,\n",
       " 88,\n",
       " 57,\n",
       " 144,\n",
       " 30,\n",
       " 134,\n",
       " 75,\n",
       " 64,\n",
       " 130,\n",
       " 189,\n",
       " 29,\n",
       " 84,\n",
       " 158,\n",
       " 122,\n",
       " 47,\n",
       " 28,\n",
       " 27,\n",
       " 155,\n",
       " 82,\n",
       " 142,\n",
       " 172,\n",
       " 19,\n",
       " 72,\n",
       " 32,\n",
       " 45,\n",
       " 31,\n",
       " 67,\n",
       " 148,\n",
       " 58,\n",
       " 124,\n",
       " 80,\n",
       " 289,\n",
       " 120,\n",
       " 76,\n",
       " 161,\n",
       " 34,\n",
       " 22,\n",
       " 40,\n",
       " 108,\n",
       " 48,\n",
       " 25,\n",
       " 56,\n",
       " 110,\n",
       " 152,\n",
       " 122,\n",
       " 159,\n",
       " 78,\n",
       " 34,\n",
       " 46,\n",
       " 29,\n",
       " 45,\n",
       " 42,\n",
       " 20,\n",
       " 43,\n",
       " 73,\n",
       " 50,\n",
       " 42,\n",
       " 76,\n",
       " 22,\n",
       " 32,\n",
       " 32,\n",
       " 36,\n",
       " 14,\n",
       " 55,\n",
       " 121,\n",
       " 144,\n",
       " 42,\n",
       " 41,\n",
       " 58,\n",
       " 195,\n",
       " 141,\n",
       " 137,\n",
       " 107,\n",
       " 158,\n",
       " 33,\n",
       " 51,\n",
       " 178,\n",
       " 31,\n",
       " 57,\n",
       " 81,\n",
       " 76,\n",
       " 160,\n",
       " 183,\n",
       " 44,\n",
       " 95,\n",
       " 43,\n",
       " 82,\n",
       " 115,\n",
       " 30,\n",
       " 40,\n",
       " 31,\n",
       " 96,\n",
       " 158,\n",
       " 143,\n",
       " 156,\n",
       " 152,\n",
       " 72,\n",
       " 86,\n",
       " 144,\n",
       " 156,\n",
       " 53,\n",
       " 156,\n",
       " 52,\n",
       " 38,\n",
       " 20,\n",
       " 244,\n",
       " 22,\n",
       " 107,\n",
       " 28,\n",
       " 9,\n",
       " 39,\n",
       " 25,\n",
       " 125,\n",
       " 162,\n",
       " 38,\n",
       " 34,\n",
       " 46,\n",
       " 155,\n",
       " 85,\n",
       " 33,\n",
       " 27,\n",
       " 156,\n",
       " 42,\n",
       " 25,\n",
       " 48,\n",
       " 159,\n",
       " 84,\n",
       " 33,\n",
       " 30,\n",
       " 45,\n",
       " 59,\n",
       " 25,\n",
       " 160,\n",
       " 384,\n",
       " 28,\n",
       " 27,\n",
       " 157,\n",
       " 124,\n",
       " 145,\n",
       " 115,\n",
       " 64,\n",
       " 85,\n",
       " 152,\n",
       " 155,\n",
       " 51,\n",
       " 156,\n",
       " 74,\n",
       " 67,\n",
       " 59,\n",
       " 50,\n",
       " 94,\n",
       " 33,\n",
       " 105,\n",
       " 61,\n",
       " 65,\n",
       " 26,\n",
       " 146,\n",
       " 66,\n",
       " 126,\n",
       " 159,\n",
       " 23,\n",
       " 65,\n",
       " 24,\n",
       " 26,\n",
       " 152,\n",
       " 34,\n",
       " 147,\n",
       " 55,\n",
       " 88,\n",
       " 72,\n",
       " 185,\n",
       " 37,\n",
       " 111,\n",
       " 92,\n",
       " 28,\n",
       " 28,\n",
       " 64,\n",
       " 131,\n",
       " 40,\n",
       " 28,\n",
       " 84,\n",
       " 174,\n",
       " 24,\n",
       " 25,\n",
       " 63,\n",
       " 156,\n",
       " 28,\n",
       " 86,\n",
       " 39,\n",
       " 73,\n",
       " 26,\n",
       " 23,\n",
       " 23,\n",
       " 31,\n",
       " 58,\n",
       " 48,\n",
       " 41,\n",
       " 32,\n",
       " 159,\n",
       " 25,\n",
       " 161,\n",
       " 22,\n",
       " 119,\n",
       " 142,\n",
       " 69,\n",
       " 137,\n",
       " 30,\n",
       " 165,\n",
       " 34,\n",
       " 109,\n",
       " 37,\n",
       " 33,\n",
       " 48,\n",
       " 157,\n",
       " 50,\n",
       " 65,\n",
       " 38,\n",
       " 145,\n",
       " 145,\n",
       " 51,\n",
       " 45,\n",
       " 83,\n",
       " 155,\n",
       " 37,\n",
       " 78,\n",
       " 30,\n",
       " 31,\n",
       " 146,\n",
       " 150,\n",
       " 44,\n",
       " 179,\n",
       " 27,\n",
       " 179,\n",
       " 38,\n",
       " 97,\n",
       " 43,\n",
       " 36,\n",
       " 154,\n",
       " 72,\n",
       " 3,\n",
       " 85,\n",
       " 51,\n",
       " 121,\n",
       " 26,\n",
       " 35,\n",
       " 47,\n",
       " 159,\n",
       " 47,\n",
       " 133,\n",
       " 53,\n",
       " 147,\n",
       " 155,\n",
       " 37,\n",
       " 31,\n",
       " 8,\n",
       " 38,\n",
       " 30,\n",
       " 47,\n",
       " 56,\n",
       " 22,\n",
       " 141,\n",
       " 29,\n",
       " 7,\n",
       " 121,\n",
       " 58,\n",
       " 4,\n",
       " 148,\n",
       " 160,\n",
       " 152,\n",
       " 37,\n",
       " 55,\n",
       " 21,\n",
       " 22,\n",
       " 50,\n",
       " 159,\n",
       " 67,\n",
       " 153,\n",
       " 51,\n",
       " 67,\n",
       " 88,\n",
       " 157,\n",
       " 91,\n",
       " 24,\n",
       " 146,\n",
       " 57,\n",
       " 26,\n",
       " 71,\n",
       " 138,\n",
       " 55,\n",
       " 156,\n",
       " 133,\n",
       " 119,\n",
       " 142,\n",
       " 41,\n",
       " 26,\n",
       " 119,\n",
       " 46,\n",
       " 157,\n",
       " 23,\n",
       " 51,\n",
       " 62,\n",
       " 107,\n",
       " 157,\n",
       " 30,\n",
       " 32,\n",
       " 31,\n",
       " 79,\n",
       " 32,\n",
       " 86,\n",
       " 22,\n",
       " 76,\n",
       " 128,\n",
       " 232,\n",
       " 158,\n",
       " 45,\n",
       " 57,\n",
       " 26,\n",
       " 22,\n",
       " 41,\n",
       " 28,\n",
       " 151,\n",
       " 29,\n",
       " 34,\n",
       " 52,\n",
       " 33,\n",
       " 85,\n",
       " 31,\n",
       " 111,\n",
       " 78,\n",
       " 50,\n",
       " 63,\n",
       " 148,\n",
       " 129,\n",
       " 45,\n",
       " 202,\n",
       " 150,\n",
       " 148,\n",
       " 168,\n",
       " 85,\n",
       " 38,\n",
       " 15,\n",
       " 31,\n",
       " 88,\n",
       " 160,\n",
       " 50,\n",
       " 165,\n",
       " 129,\n",
       " 26,\n",
       " 31,\n",
       " 129,\n",
       " 34,\n",
       " 54,\n",
       " 162,\n",
       " 157,\n",
       " 23,\n",
       " 53,\n",
       " 131,\n",
       " 36,\n",
       " 143,\n",
       " 300,\n",
       " 59,\n",
       " 42,\n",
       " 41,\n",
       " 149,\n",
       " 22,\n",
       " 31,\n",
       " 30,\n",
       " 155,\n",
       " 47,\n",
       " 25,\n",
       " 80,\n",
       " 22,\n",
       " 115,\n",
       " 56,\n",
       " 102,\n",
       " 118,\n",
       " 221,\n",
       " 204,\n",
       " 114,\n",
       " 156,\n",
       " 39,\n",
       " 36,\n",
       " 48,\n",
       " 77,\n",
       " 60,\n",
       " 168,\n",
       " 51,\n",
       " 22,\n",
       " 152,\n",
       " 75,\n",
       " 30,\n",
       " 95,\n",
       " 24,\n",
       " 49,\n",
       " 35,\n",
       " 29,\n",
       " 106,\n",
       " 66,\n",
       " 159,\n",
       " 48,\n",
       " 162,\n",
       " 24,\n",
       " 136,\n",
       " 248,\n",
       " 25,\n",
       " 27,\n",
       " 37,\n",
       " 68,\n",
       " 150,\n",
       " 24,\n",
       " 80,\n",
       " 157,\n",
       " 25,\n",
       " 73,\n",
       " 89,\n",
       " 58,\n",
       " 36,\n",
       " 76,\n",
       " 47,\n",
       " 104,\n",
       " 38,\n",
       " 69,\n",
       " 22,\n",
       " 119,\n",
       " 94,\n",
       " 70,\n",
       " 73,\n",
       " 42,\n",
       " 17,\n",
       " 13,\n",
       " 45,\n",
       " 57,\n",
       " 105,\n",
       " 162,\n",
       " 47,\n",
       " 115,\n",
       " 158,\n",
       " 79,\n",
       " 142,\n",
       " 62,\n",
       " 71,\n",
       " 175,\n",
       " 29,\n",
       " 29,\n",
       " 148,\n",
       " 83,\n",
       " 37,\n",
       " 44,\n",
       " 45,\n",
       " 161,\n",
       " 50,\n",
       " 298,\n",
       " 159,\n",
       " 125,\n",
       " 51,\n",
       " 28,\n",
       " 34,\n",
       " 46,\n",
       " 81,\n",
       " 28,\n",
       " 90,\n",
       " 18,\n",
       " 54,\n",
       " 55,\n",
       " 45,\n",
       " 146,\n",
       " 40,\n",
       " 107,\n",
       " 50,\n",
       " 120,\n",
       " 160,\n",
       " 32,\n",
       " 34,\n",
       " 32,\n",
       " 16,\n",
       " 67,\n",
       " 55,\n",
       " 43,\n",
       " 23,\n",
       " 149,\n",
       " 20,\n",
       " 23,\n",
       " 40,\n",
       " 169,\n",
       " 117,\n",
       " 62,\n",
       " 166,\n",
       " 24,\n",
       " 136,\n",
       " 99,\n",
       " 45,\n",
       " 23,\n",
       " 25,\n",
       " 147,\n",
       " 26,\n",
       " 146,\n",
       " 89,\n",
       " 168,\n",
       " 117,\n",
       " 46,\n",
       " 26,\n",
       " 28,\n",
       " 32,\n",
       " 144,\n",
       " 57,\n",
       " 158,\n",
       " 42,\n",
       " 111,\n",
       " 36,\n",
       " 146,\n",
       " 50,\n",
       " 33,\n",
       " 15,\n",
       " 177,\n",
       " 160,\n",
       " 63,\n",
       " 84,\n",
       " 84,\n",
       " 57,\n",
       " 96,\n",
       " 169,\n",
       " 76,\n",
       " 47,\n",
       " 130,\n",
       " 23,\n",
       " 149,\n",
       " 32,\n",
       " 22,\n",
       " 101,\n",
       " 281,\n",
       " 54,\n",
       " 120,\n",
       " 138,\n",
       " 127,\n",
       " 66,\n",
       " 40,\n",
       " 40,\n",
       " 70,\n",
       " 160,\n",
       " 26,\n",
       " 32,\n",
       " 51,\n",
       " 159,\n",
       " 146,\n",
       " 103,\n",
       " 45,\n",
       " 142,\n",
       " 92,\n",
       " 26,\n",
       " 134,\n",
       " 37,\n",
       " 22,\n",
       " 22,\n",
       " 33,\n",
       " 69,\n",
       " 109,\n",
       " 35,\n",
       " 99,\n",
       " 140,\n",
       " 50,\n",
       " 46,\n",
       " 149,\n",
       " 63,\n",
       " 95,\n",
       " 69,\n",
       " 110,\n",
       " 51,\n",
       " 27,\n",
       " 34,\n",
       " 126,\n",
       " 142,\n",
       " 148,\n",
       " 24,\n",
       " 147,\n",
       " 24,\n",
       " 29,\n",
       " 86,\n",
       " 87,\n",
       " 38,\n",
       " 104,\n",
       " 59,\n",
       " 38,\n",
       " 38,\n",
       " 22,\n",
       " 25,\n",
       " 135,\n",
       " 87,\n",
       " 19,\n",
       " 66,\n",
       " 140,\n",
       " 156,\n",
       " 22,\n",
       " 107,\n",
       " 65,\n",
       " 145,\n",
       " 137,\n",
       " 25,\n",
       " 59,\n",
       " 103,\n",
       " 37,\n",
       " 58,\n",
       " 87,\n",
       " 58,\n",
       " 123,\n",
       " 67,\n",
       " 66,\n",
       " 102,\n",
       " 130,\n",
       " 148,\n",
       " 35,\n",
       " 8,\n",
       " 62,\n",
       " 56,\n",
       " 143,\n",
       " 20,\n",
       " 100,\n",
       " 49,\n",
       " 36,\n",
       " 53,\n",
       " 88,\n",
       " 133,\n",
       " 36,\n",
       " 37,\n",
       " 123,\n",
       " 92,\n",
       " 80,\n",
       " 136,\n",
       " 35,\n",
       " 97,\n",
       " 66,\n",
       " 119,\n",
       " 65,\n",
       " 26,\n",
       " 28,\n",
       " 45,\n",
       " 157,\n",
       " 36,\n",
       " 94,\n",
       " 59,\n",
       " 140,\n",
       " 22,\n",
       " 56,\n",
       " 43,\n",
       " 61,\n",
       " 56,\n",
       " 54,\n",
       " 37,\n",
       " 25,\n",
       " 21,\n",
       " 36,\n",
       " 93,\n",
       " 153,\n",
       " 153,\n",
       " 46,\n",
       " 34,\n",
       " 80,\n",
       " 69,\n",
       " 24,\n",
       " 108,\n",
       " 46,\n",
       " 29,\n",
       " 22,\n",
       " 158,\n",
       " 86,\n",
       " 30,\n",
       " 143,\n",
       " 169,\n",
       " 42,\n",
       " 111,\n",
       " 18,\n",
       " 109,\n",
       " 76,\n",
       " 73,\n",
       " 92,\n",
       " 36,\n",
       " 54,\n",
       " 76,\n",
       " 29,\n",
       " 40,\n",
       " 28,\n",
       " 22,\n",
       " 77,\n",
       " 109,\n",
       " 75,\n",
       " 76,\n",
       " 30,\n",
       " 49,\n",
       " 155,\n",
       " 160,\n",
       " 316,\n",
       " 195,\n",
       " 37,\n",
       " 125,\n",
       " 48,\n",
       " 39,\n",
       " 161,\n",
       " 121,\n",
       " 145,\n",
       " 162,\n",
       " 29,\n",
       " 38,\n",
       " 25,\n",
       " 40,\n",
       " 226,\n",
       " 70,\n",
       " 140,\n",
       " 47,\n",
       " 63,\n",
       " 17,\n",
       " 101,\n",
       " 41,\n",
       " 80,\n",
       " 137,\n",
       " 103,\n",
       " 29,\n",
       " 51,\n",
       " 148,\n",
       " 25,\n",
       " 149,\n",
       " 38,\n",
       " 62,\n",
       " 179,\n",
       " 34,\n",
       " 47,\n",
       " 40,\n",
       " 110,\n",
       " 131,\n",
       " 101,\n",
       " 42,\n",
       " 102,\n",
       " 65,\n",
       " 27,\n",
       " 31,\n",
       " 82,\n",
       " 23,\n",
       " 59,\n",
       " 133,\n",
       " 33,\n",
       " 95,\n",
       " 95,\n",
       " 135,\n",
       " 159,\n",
       " 151,\n",
       " 73,\n",
       " 149,\n",
       " 103,\n",
       " 22,\n",
       " 51,\n",
       " 137,\n",
       " 58,\n",
       " 89,\n",
       " 81,\n",
       " 57,\n",
       " 26,\n",
       " 32,\n",
       " 145,\n",
       " 118,\n",
       " 143,\n",
       " 23,\n",
       " 136,\n",
       " 94,\n",
       " 8,\n",
       " 99,\n",
       " 65,\n",
       " 71,\n",
       " 117,\n",
       " 129,\n",
       " 157,\n",
       " 28,\n",
       " 150,\n",
       " 31,\n",
       " 71,\n",
       " 70,\n",
       " 94,\n",
       " 48,\n",
       " 160,\n",
       " 94,\n",
       " 31,\n",
       " 39,\n",
       " 152,\n",
       " 71,\n",
       " 162,\n",
       " 141,\n",
       " 25,\n",
       " 22,\n",
       " 48,\n",
       " 33,\n",
       " 44,\n",
       " 47,\n",
       " 26,\n",
       " 112,\n",
       " 148,\n",
       " 19,\n",
       " 133,\n",
       " 48,\n",
       " 107,\n",
       " 38,\n",
       " 27,\n",
       " 124,\n",
       " 131,\n",
       " 23,\n",
       " 156,\n",
       " 161,\n",
       " 25,\n",
       " 42,\n",
       " 27,\n",
       " 22,\n",
       " 98,\n",
       " 89,\n",
       " 147,\n",
       " 129,\n",
       " 152,\n",
       " 215,\n",
       " 26,\n",
       " 66,\n",
       " 149,\n",
       " 372,\n",
       " 155,\n",
       " 160,\n",
       " 81,\n",
       " 73,\n",
       " 76,\n",
       " 153,\n",
       " 24,\n",
       " 231,\n",
       " 87,\n",
       " 72,\n",
       " 105,\n",
       " 158,\n",
       " 54,\n",
       " 58,\n",
       " 54,\n",
       " 114,\n",
       " 88,\n",
       " 144,\n",
       " 29,\n",
       " 136,\n",
       " 23,\n",
       " 39,\n",
       " 35,\n",
       " 24,\n",
       " 95,\n",
       " 73,\n",
       " 45,\n",
       " 160,\n",
       " 159,\n",
       " 149,\n",
       " 134,\n",
       " 154,\n",
       " 92,\n",
       " 102,\n",
       " 31,\n",
       " 77,\n",
       " 139,\n",
       " 156,\n",
       " 44,\n",
       " 136,\n",
       " 132,\n",
       " 143,\n",
       " 127,\n",
       " 276,\n",
       " 78,\n",
       " 27,\n",
       " 79,\n",
       " 24,\n",
       " 52,\n",
       " 68,\n",
       " 24,\n",
       " 44,\n",
       " 24,\n",
       " 55,\n",
       " 62,\n",
       " 104,\n",
       " 87,\n",
       " 148,\n",
       " 49,\n",
       " 154,\n",
       " 56,\n",
       " 158,\n",
       " 126,\n",
       " 43,\n",
       " 77,\n",
       " 49,\n",
       " 84,\n",
       " 49,\n",
       " 162,\n",
       " 79,\n",
       " 31,\n",
       " 155,\n",
       " 146,\n",
       " 23,\n",
       " 160,\n",
       " 62,\n",
       " 39,\n",
       " 67,\n",
       " 73,\n",
       " 148,\n",
       " 88,\n",
       " 37,\n",
       " 23,\n",
       " 56,\n",
       " 53,\n",
       " 73,\n",
       " 80,\n",
       " 44,\n",
       " 92,\n",
       " 35,\n",
       " 23,\n",
       " 139,\n",
       " 106,\n",
       " 103,\n",
       " 34,\n",
       " 77,\n",
       " 158,\n",
       " 26,\n",
       " 47,\n",
       " 24,\n",
       " 148,\n",
       " 133,\n",
       " 126,\n",
       " 78,\n",
       " 132,\n",
       " 116,\n",
       " 221,\n",
       " 59,\n",
       " 137,\n",
       " 143,\n",
       " 24,\n",
       " 38,\n",
       " 42,\n",
       " 24,\n",
       " 157,\n",
       " 47,\n",
       " 41,\n",
       " 122,\n",
       " 126,\n",
       " 26,\n",
       " 114,\n",
       " 7,\n",
       " 34,\n",
       " 156,\n",
       " 92,\n",
       " 90,\n",
       " 22,\n",
       " 85,\n",
       " 63,\n",
       " 220,\n",
       " 41,\n",
       " 60,\n",
       " 88,\n",
       " 31,\n",
       " 37,\n",
       " 28,\n",
       " 24,\n",
       " 118,\n",
       " 22,\n",
       " 210,\n",
       " 50,\n",
       " 49,\n",
       " 87,\n",
       " 61,\n",
       " 141,\n",
       " 54,\n",
       " 28,\n",
       " 49,\n",
       " 53,\n",
       " 145,\n",
       " 160,\n",
       " 53,\n",
       " 12,\n",
       " 142,\n",
       " 71,\n",
       " 129,\n",
       " 33,\n",
       " 47,\n",
       " 72,\n",
       " 148,\n",
       " 104,\n",
       " ...]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Length column to the dataframe\n",
    "messages['Length']=length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            Message  Length\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1   ham                      Ok lar... Joking wif u oni...      29\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "3   ham  U dun say so early hor... U c already then say...      49\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating Punctuations in each message**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Punctuations in each message\n",
    "\n",
    "import string\n",
    "count=0\n",
    "punct=[]\n",
    "for i in range(len(messages)):\n",
    "    for j in messages['Message'][i]:\n",
    "        if j in string.punctuation:\n",
    "            count+=1\n",
    "    #print(count)\n",
    "    punct.append(count)\n",
    "    count=0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 11,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 15,\n",
       " 5,\n",
       " 1,\n",
       " 10,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 11,\n",
       " 1,\n",
       " 14,\n",
       " 5,\n",
       " 6,\n",
       " 12,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 10,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 15,\n",
       " 13,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 12,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 16,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 13,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 12,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 14,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 0,\n",
       " 16,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 13,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 11,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 12,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 14,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 11,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 12,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 14,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 11,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 15,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 10,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 14,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 10,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 11,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 14,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 11,\n",
       " 11,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 12,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 30,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 17,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 9,\n",
       " 17,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 11,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 18,\n",
       " 7,\n",
       " 10,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 12,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 12,\n",
       " 2,\n",
       " 12,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 10,\n",
       " 4,\n",
       " 10,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 15,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 19,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 16,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 12,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 11,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 13,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 11,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 11,\n",
       " 2,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 10,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 23,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 10,\n",
       " 5,\n",
       " 13,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 12,\n",
       " 4,\n",
       " 5,\n",
       " 10,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 12,\n",
       " 11,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 11,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 10,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 10,\n",
       " 5,\n",
       " 1,\n",
       " 10,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 13,\n",
       " 8,\n",
       " 2,\n",
       " 14,\n",
       " 0,\n",
       " 13,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 10,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 10,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 19,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 11,\n",
       " 4,\n",
       " 1,\n",
       " 11,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 11,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 13,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 13,\n",
       " 12,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 9,\n",
       " 11,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " ...]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding punctuation length column to dataframe\n",
    "messages[\"Punctuation\"]=punct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regex\n",
    "import re\n",
    "\n",
    "#Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#Creating object for Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removal of extra characters and stop words and lemmatization\n",
    "corpus = []\n",
    "\n",
    "#Skipping the 0th index (it's of Label)\n",
    "for i in range(0,len(messages)):\n",
    "    words = re.sub('[^a-zA-Z]',' ',messages['Message'][i])\n",
    "    words = words.lower()\n",
    "    #Splits into list of words \n",
    "    words = words.split()\n",
    "    \n",
    "    #Lemmatizing the word and removing the stopwords\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    \n",
    "    #Again join words to form sentences\n",
    "    words = ' '.join(words)\n",
    "    \n",
    "    corpus.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go jurong point crazy available bugis n great world la e buffet cine got amore wat'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What's in Corpus\n",
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing Original Message with the Transformed Messages\n",
    "messages['Message'] = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "      <th>Length</th>\n",
       "      <th>Punctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah think go usf life around though</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            Message  Length  \\\n",
       "0   ham  go jurong point crazy available bugis n great ...     111   \n",
       "1   ham                            ok lar joking wif u oni      29   \n",
       "2  spam  free entry wkly comp win fa cup final tkts st ...     155   \n",
       "3   ham                u dun say early hor u c already say      49   \n",
       "4   ham                nah think go usf life around though      61   \n",
       "\n",
       "   Punctuation  \n",
       "0            9  \n",
       "1            6  \n",
       "2            6  \n",
       "3            6  \n",
       "4            2  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Analyzing the difference between Spam and Ham messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_messages = messages[messages['Label'] == 'spam']\n",
    "ham_messages = messages[messages['Label'] == 'ham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "      <th>Length</th>\n",
       "      <th>Punctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>freemsg hey darling week word back like fun st...</td>\n",
       "      <td>147</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>winner valued network customer selected receiv...</td>\n",
       "      <td>157</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>mobile month u r entitled update latest colour...</td>\n",
       "      <td>154</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>six chance win cash pound txt csh send cost p ...</td>\n",
       "      <td>136</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                            Message  Length  \\\n",
       "2   spam  free entry wkly comp win fa cup final tkts st ...     155   \n",
       "5   spam  freemsg hey darling week word back like fun st...     147   \n",
       "8   spam  winner valued network customer selected receiv...     157   \n",
       "9   spam  mobile month u r entitled update latest colour...     154   \n",
       "11  spam  six chance win cash pound txt csh send cost p ...     136   \n",
       "\n",
       "    Punctuation  \n",
       "2             6  \n",
       "5             8  \n",
       "8             6  \n",
       "9             2  \n",
       "11            8  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "      <th>Length</th>\n",
       "      <th>Punctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah think go usf life around though</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>even brother like speak treat like aid patent</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            Message  Length  \\\n",
       "0   ham  go jurong point crazy available bugis n great ...     111   \n",
       "1   ham                            ok lar joking wif u oni      29   \n",
       "3   ham                u dun say early hor u c already say      49   \n",
       "4   ham                nah think go usf life around though      61   \n",
       "6   ham      even brother like speak treat like aid patent      77   \n",
       "\n",
       "   Punctuation  \n",
       "0            9  \n",
       "1            6  \n",
       "3            6  \n",
       "4            2  \n",
       "6            2  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138.6706827309237"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_messages['Length'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.48248704663213"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_messages['Length'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Spam messages have more average words than Ham messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.712182061579652"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_messages['Punctuation'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9398963730569947"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_messages['Punctuation'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same with Punctuation also, We can see that Spam messages have more average punctuation than Ham messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = messages['Message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    go jurong point crazy available bugis n great ...\n",
       "1                              ok lar joking wif u oni\n",
       "2    free entry wkly comp win fa cup final tkts st ...\n",
       "3                  u dun say early hor u c already say\n",
       "4                  nah think go usf life around though\n",
       "Name: Message, dtype: object"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = messages['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     ham\n",
       "1     ham\n",
       "2    spam\n",
       "3     ham\n",
       "4     ham\n",
       "Name: Label, dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X , y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3235                                            yup comin\n",
       "945     sent score sophas secondary application school...\n",
       "5319                              kothi print marandratha\n",
       "5528                             effect irritation ignore\n",
       "247                                         asked call ok\n",
       "Name: Message, dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration of Count Vectorizer\n",
    "\n",
    "(Bag of Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_count_vect=count_vect.fit_transform(X_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_count_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3733, 5772)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3733 are the sentences and 5772 are the words in total sentences\n",
    "X_train_count_vect.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:-**<br>\n",
    "There might be that, some words in 5772 words are not frequently present and are just appearing 1-2 times, we can reduce them using cv = CountVectorizer(max_features = 4000) (an approach)\n",
    "\n",
    "This will only take 4000 words leading to coming of most frequent words\n",
    "\n",
    "    We can change the max_features, according to what we want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration of TF-IDF Vectorizer\n",
    "\n",
    "(Term Frequency - Inverse Document Frequency)\n",
    "\n",
    "\n",
    "CountVectorizer(Bag of Words) + TFIDF Transformer, Scikit-Learn has provided with a method of TFIDF vectorizer (combining two steps into one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf_vect=count_vect.fit_transform(X_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3733, 5772)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf_vect.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelining\n",
    "\n",
    "We are doing pipelining as we need to perform the same procedures for the test data to get predictions, that may be tiresome.\n",
    "\n",
    "However what convenient about this pipeline object is that it actually can perform all these steps for you in a single cell, that means you can directly provide the data and it will be both vectorized and run the classifier on it in a single step.\n",
    "\n",
    "Pipeline takes list of tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayer Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each tuple takes the name you decide , next you call what you want to occur\n",
    "text_mnb=Pipeline([('tfidf',TfidfVectorizer()),('mnb',MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('mnb', MultinomialNB())])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now u can directly pass the X_train dataset.\n",
    "text_mnb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3245    squeeeeeze christmas hug u lik frndshp den hug...\n",
       "944     also sorta blown couple time recently id rathe...\n",
       "1044    mmm thats better got roast b better drink good...\n",
       "2484                  mm kanji dont eat anything heavy ok\n",
       "812     ring come guy costume gift future yowifes hint...\n",
       "Name: Message, dtype: object"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It will take the X_test and do all the steps, vectorize it and predict it\n",
    "y_preds_mnb=text_mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'ham', 'ham', ..., 'ham', 'ham', 'ham'], dtype='<U4')"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predictions of the test data\n",
    "y_preds_mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975622823466381"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training score\n",
    "text_mnb.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9700924415443176"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing score\n",
    "text_mnb.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1592    1]\n",
      " [  54  192]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_preds_mnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.98      1593\n",
      "        spam       0.99      0.78      0.87       246\n",
      "\n",
      "    accuracy                           0.97      1839\n",
      "   macro avg       0.98      0.89      0.93      1839\n",
      "weighted avg       0.97      0.97      0.97      1839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_preds_mnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each tuple takes the name you decide , next you call what you want to occur\n",
    "text_svm=Pipeline([('tfidf',TfidfVectorizer()),('svm',LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('svm', LinearSVC())])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now u can directly pass the X_train dataset.\n",
    "text_svm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3245    squeeeeeze christmas hug u lik frndshp den hug...\n",
       "944     also sorta blown couple time recently id rathe...\n",
       "1044    mmm thats better got roast b better drink good...\n",
       "2484                  mm kanji dont eat anything heavy ok\n",
       "812     ring come guy costume gift future yowifes hint...\n",
       "Name: Message, dtype: object"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It will take the X_test and do all the steps, vectorize it and predict it\n",
    "y_preds_svm=text_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'ham', 'ham', ..., 'ham', 'ham', 'ham'], dtype=object)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predictions of the test data\n",
    "y_preds_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training score\n",
    "text_svm.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9869494290375204"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing score\n",
    "text_svm.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1589    4]\n",
      " [  20  226]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_preds_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99      1593\n",
      "        spam       0.98      0.92      0.95       246\n",
      "\n",
      "    accuracy                           0.99      1839\n",
      "   macro avg       0.99      0.96      0.97      1839\n",
      "weighted avg       0.99      0.99      0.99      1839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_preds_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediciting on New SMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Congratulations, you have won a lottery of $5000. To Won Text on,555500 '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refined_text(text):\n",
    "    #Removal of extra characters and stop words\n",
    "    words = re.sub('[^a-zA-Z]',' ',text)\n",
    "    words = words.lower()\n",
    "    #Splits into list of words \n",
    "    words = words.split()\n",
    "\n",
    "    #Lemmatizing the word and removing the stopwords\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "\n",
    "    #Again join words to form sentences\n",
    "    words = ' '.join(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_word = refined_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_word = [refined_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['congratulation lottery text']"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam'], dtype='<U4')"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directly predicting the single message to the model\n",
    "text_mnb.predict(refined_word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
